<!DOCTYPE html>
<html lang=zh-CN>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        CUDA基础学习 - Vicczyq | 记录学习和生活
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_28hi1hpxx24.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>

    









<meta name="generator" content="Hexo 7.1.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 好好生活，保持热爱，无惧无畏，奔赴山海 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar radius">
            <img src="//q2.qlogo.cn/headimg_dl?dst_uin=1740674168&amp;spec=140" />
        </div>
        <div class="name">
            <i>Vicczyq | 长木乔</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/collect/">
                    <i class="iconfont icon-shoucang1"></i>
                    <span>收藏</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E6%A0%B8%E5%87%BD%E6%95%B0%EF%BC%88Kernel-function%EF%BC%89"><span class="toc-text">1、核函数（Kernel_function）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-text">2、线程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-text">2.1基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2%E4%B8%80%E7%BB%B4%E8%BA%AB%E4%BB%BD%E6%A0%87%E8%AF%86"><span class="toc-text">2.2一维身份标识</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81%E5%87%BD%E6%95%B0%E4%BF%AE%E9%A5%B0%E7%AC%A6"><span class="toc-text">3、函数修饰符</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4%E3%80%81%E5%B8%B8%E7%94%A8%E7%9A%84GPU%E5%87%BD%E6%95%B0"><span class="toc-text">4、常用的GPU函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cudaMalloc-void-devPtr-size-t-size"><span class="toc-text">cudaMalloc (void **devPtr, size_t size)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cudaMemcpy-void-dst-const-void-src-size-t-count-cudaMemcpyKind-kind"><span class="toc-text">cudaMemcpy (void dst, const void src, size_t count, cudaMemcpyKind kind)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cudaFree-void-devPtr"><span class="toc-text">cudaFree ( void* devPtr )</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#syncthreads"><span class="toc-text">__syncthreads()</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cudaDeviceSynchronize"><span class="toc-text">cudaDeviceSynchronize();</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5%E3%80%81GPU%E5%86%85%E5%AD%98%E5%88%86%E7%B1%BB"><span class="toc-text">5、GPU内存分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98"><span class="toc-text">5.1全局内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="toc-text">5.2共享内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98"><span class="toc-text">5.3常量内存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6%E3%80%81%E8%AE%A1%E6%97%B6"><span class="toc-text">6、计时</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7%E3%80%81%E8%8E%B7%E5%8F%96GPU%E5%90%8D%E5%AD%97"><span class="toc-text">7、获取GPU名字</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8%E3%80%81%E7%BA%BF%E7%A8%8B%E6%9D%9F%EF%BC%88Wrap"><span class="toc-text">8、线程束（Wrap)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9%E3%80%81%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEgrid%E5%92%8Cblock"><span class="toc-text">9、如何设置grid和block</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%80%EF%BC%9A"><span class="toc-text">前言：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AEgrid%E5%92%8Cblock%E7%BB%B4%E5%BA%A6"><span class="toc-text">设置grid和block维度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E4%B8%80%E7%BB%B4grid%EF%BC%8C%E4%B8%80%E7%BB%B4block"><span class="toc-text">1.一维grid，一维block</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%BA%8C%E7%BB%B4grid%EF%BC%8C%E4%B8%80%E7%BB%B4block"><span class="toc-text">2.二维grid，一维block</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%BA%8C%E7%BB%B4grid%EF%BC%8C%E4%BA%8C%E7%BB%B4block"><span class="toc-text">3.二维grid，二维block</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%A1%A3"><span class="toc-text">文档</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-bg" id="search-bg"></div>
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 好好生活，保持热爱，无惧无畏，奔赴山海 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        CUDA基础学习
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2022-02-05 19:28:27</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#超算" title="超算">超算</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1699278155036-757a1974-f6c1-43cd-a8e6-06852e4e6a4f.png" alt="img"></p>
<p>CPU+GPU组成异构计算，GPU可以看做是CPU的协作处理器，一般称为设备</p>
<p>主机（CPU）和设备（GPU）之间的内存访问是通过PCIe总线连接的</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>CPU</strong></th>
<th><strong>GPU</strong></th>
<th><strong>层次</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>算术逻辑和控制单元</td>
<td>流处理器(SM)</td>
<td>硬件</td>
</tr>
<tr>
<td>算术单元</td>
<td>批量处理器(SP)</td>
<td>硬件</td>
</tr>
<tr>
<td>进程</td>
<td>Block</td>
<td>软件</td>
</tr>
<tr>
<td>线程</td>
<td>thread</td>
<td>软件</td>
</tr>
<tr>
<td>调度单位</td>
<td>Warp</td>
<td>软件</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1699013132500-689d59c7-7782-48d7-b23b-7cde1c59474d.png" alt="img"></p>
<p>一个线程在一个CUDA Core执行（SP）</p>
<p>一个线程块被分配到一个SM上面执行</p>
<p>一个Grid在GPU设备执行</p>
<p><strong>查看显卡利用率</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1699002941511-a35e1dac-97f6-4a68-b917-50814844d2dc.png" alt="img"></p>
<h2 id="1、核函数（Kernel-function）"><a href="#1、核函数（Kernel-function）" class="headerlink" title="1、核函数（Kernel_function）"></a>1、核函数（Kernel_function）</h2><p>核函数在GPU上进行并行执行</p>
<p>注意：</p>
<ol>
<li>限定词_global_修饰</li>
<li>返回值必须是void</li>
<li>核函数只能访问设备（GPU）内存</li>
<li>核函数不能使用变长参数、静态变量、函数指针</li>
<li>核函数具有异步性</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">_global_ <span class="type">void</span> <span class="title">kernel_function</span><span class="params">(argument *arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world from GPU\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> _global_ <span class="title">kernel_function</span><span class="params">(argument *arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world from GPU\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">_global__ <span class="type">void</span> <span class="title">hello</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world from GPU\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    hello&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;(); <span class="comment">//设备（GPU）核函数执行，&lt;&lt;&lt;1,1&gt;&gt;&gt;含义见下节。</span></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>(); <span class="comment">//同步，CPU等待CPU处理完成</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2、线程模型"><a href="#2、线程模型" class="headerlink" title="2、线程模型"></a>2、线程模型</h2><h3 id="2-1基本概念"><a href="#2-1基本概念" class="headerlink" title="2.1基本概念"></a>2.1基本概念</h3><div class="table-container">
<table>
<thead>
<tr>
<th>网格 grid</th>
<th>线程块 block</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1699011161039-62e75ab2-9f1c-4917-a815-37284fa75aa2.jpeg" alt="img"></p>
<p>线程分块是逻辑上的划分，物理上线程不分块</p>
<p>配置线程：<code>&lt;&lt;&lt;grid_size , block_size&gt;&gt;&gt;</code></p>
<p>grid_size：网格包含的线程块个数    block_size：线程块包含的线程个数</p>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1697013915734-f63e760a-5105-44f8-bafe-e9c5b382fe85.png" alt="img"></p>
<h3 id="2-2一维身份标识"><a href="#2-2一维身份标识" class="headerlink" title="2.2一维身份标识"></a>2.2一维身份标识</h3><p>每个线程的唯一标识由<code>&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;</code>确定。</p>
<p>在核函数中可以使用</p>
<p><code>gridDim.x</code>：该变量的值等于执行配置中变量<code>grid_size</code>的值（线程格的维度）</p>
<p><code>blockDim.x</code>：该变量的值等于执行配置中变量<code>block_size</code>的值（线程块的维度）</p>
<p><code>blockIdx.x</code>：线程在网格(grid)中的线程块(block)的索引，范围<code>0~gridDim.x-1</code>（线程块的索引）</p>
<p><code>threadIdx.x</code>：线程在线程块中的线程索引，范围<code>0~blockDim.x-1</code>（线程索引）</p>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1697012880220-f0efb73d-8784-47bf-bed8-34e3663ca4a5.png" alt="img"></p>
<p>CUDA可以组织三维的网格和线程块</p>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1829f7dfa12f09c2cfa0bde303e7d892.svg+xml" alt="img"><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/96699848a0c6e08f2eb50a52efcefc44.svg+xml" alt="img"></p>
<p><code>blockIdx</code>和<code>threadIdx</code>都是结构体，具有x，y，z三个成员</p>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1697013503445-bdade019-0e4f-4dbe-91f9-35edef6a38ea.png" alt="img"></p>
<p><strong>一维：</strong></p>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1697013590396-76aec282-966a-48f7-804b-3cd0220a7cd4.png" alt="img"></p>
<p><strong>多维：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid_size</span><span class="params">(Gx,Gy,Gz)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block_size</span><span class="params">(Bx,By,Bz)</span></span>;</span><br><span class="line">&lt;&lt;&lt;grid_size,block_size&gt;&gt;&gt;<span class="comment">//（线程块数，每个块线程数）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如：</span></span><br><span class="line">    <span class="function">dim3 <span class="title">grid_size</span><span class="params">(<span class="number">2</span>,<span class="number">2</span>)</span></span>; <span class="comment">//等价于dim3 grid_size(2,2,1);</span></span><br><span class="line">	<span class="function">dim3 <span class="title">block_size</span><span class="params">(<span class="number">5</span>,<span class="number">3</span>)</span></span>;<span class="comment">//等价于dim3 block_size(5,3,1);</span></span><br></pre></td></tr></table></figure>
<h2 id="3、函数修饰符"><a href="#3、函数修饰符" class="headerlink" title="3、函数修饰符"></a>3、函数修饰符</h2><p><strong><strong>global</strong></strong>：表明被修饰的函数在设备上执行，但在主机上调用</p>
<p><strong><strong>device</strong></strong>：表明被修饰的函数在设备上执行，但只能在其他<strong>device</strong>函数或者<strong>global</strong>函数中调用。</p>
<h2 id="4、常用的GPU函数"><a href="#4、常用的GPU函数" class="headerlink" title="4、常用的GPU函数"></a>4、常用的GPU函数</h2><h4 id="cudaMalloc-void-devPtr-size-t-size"><a href="#cudaMalloc-void-devPtr-size-t-size" class="headerlink" title="cudaMalloc (void **devPtr, size_t size)"></a>cudaMalloc (void **devPtr, size_t size)</h4><p>功能：与C语言中的malloc函数一样，只是此函数在GPU的内存你分配内存。</p>
<h4 id="cudaMemcpy-void-dst-const-void-src-size-t-count-cudaMemcpyKind-kind"><a href="#cudaMemcpy-void-dst-const-void-src-size-t-count-cudaMemcpyKind-kind" class="headerlink" title="cudaMemcpy (void dst, const void src, size_t count, cudaMemcpyKind kind)"></a>cudaMemcpy (void dst, const void src, size_t count, cudaMemcpyKind kind)</h4><p>功能：与c语言中的memcpy函数一样，只是此函数可以在主机内存和GPU内存之间互相拷贝数据。</p>
<p>函数参数：cudaMemcpyKind kind表示数据拷贝方向，如果kind赋值cudaMemcpyDeviceToHost表示数据从设备内存拷贝到主机内存，cudaMemcpyHostToDevice表示主机到设备。</p>
<p>相应的有个异步方式执行的函数cudaMemcpyAsync()</p>
<h4 id="cudaFree-void-devPtr"><a href="#cudaFree-void-devPtr" class="headerlink" title="cudaFree ( void* devPtr )"></a>cudaFree ( void* devPtr )</h4><p>功能：与c语言中的free()函数一样，只是此函数释放的是cudaMalloc()分配的内存。</p>
<h4 id="syncthreads"><a href="#syncthreads" class="headerlink" title="__syncthreads()"></a>__syncthreads()</h4><p>功能：同步函数，确保线程块中的每个线程都执行完__syscthreads()前面的语句后，才会执行下一条语句。</p>
<h4 id="cudaDeviceSynchronize"><a href="#cudaDeviceSynchronize" class="headerlink" title="cudaDeviceSynchronize();"></a>cudaDeviceSynchronize();</h4><p>功能：同步，CPU等待GPU处理完成，注意此函数是CPU函数！</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">add</span><span class="params">( <span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> *c )</span> </span>&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">( <span class="type">void</span> )</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> c;</span><br><span class="line">    <span class="type">int</span> *dev_c;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>( (<span class="type">void</span>**)&amp;dev_c, <span class="built_in">sizeof</span>(<span class="type">int</span>) );</span><br><span class="line"></span><br><span class="line">    add&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;( <span class="number">2</span>, <span class="number">7</span>, dev_c );   </span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>( &amp;c, dev_c, <span class="built_in">sizeof</span>(<span class="type">int</span>),cudaMemcpyDeviceToHost ) ;</span><br><span class="line">    <span class="built_in">printf</span>( <span class="string">&quot;2 + 7 = %d\n&quot;</span>, c );</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>( dev_c );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5、GPU内存分类"><a href="#5、GPU内存分类" class="headerlink" title="5、GPU内存分类"></a>5、GPU内存分类</h2><h3 id="5-1全局内存"><a href="#5-1全局内存" class="headerlink" title="5.1全局内存"></a>5.1全局内存</h3><p>通俗意义上的设备内存</p>
<h3 id="5-2共享内存"><a href="#5-2共享内存" class="headerlink" title="5.2共享内存"></a>5.2共享内存</h3><p>位置：设备内存。</p>
<p>形式：关键字<code>__share__</code>添加到变量声明中，如：<code>**__share__ float a[10]**</code></p>
<p>访问速度和L1相同</p>
<h3 id="5-3常量内存"><a href="#5-3常量内存" class="headerlink" title="5.3常量内存"></a>5.3常量内存</h3><p>位置：设备内存</p>
<p>形式：关键字<code>__constant__</code>添加到变量声明中，如：<code>__constant__ float a[10]</code></p>
<p>目的：为了提升性能。常量内存采取了不同于全局内存的处理方式，在某些情况下用常量内存替换全局内存能有效的减少内存带宽。</p>
<h2 id="6、计时"><a href="#6、计时" class="headerlink" title="6、计时"></a>6、计时</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">cpuSecond</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> <span class="title class_">timeval</span> tp;</span><br><span class="line">    <span class="built_in">gettimeofday</span>(&amp;tp,<span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">return</span> ((<span class="type">double</span>)tp.tv_sec + (<span class="type">double</span>)tp.tv_usec*<span class="number">1.e-6</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">测试函数(秒)：</span><br><span class="line"><span class="type">double</span> start_time = <span class="built_in">cpuSecond</span>();</span><br><span class="line">kernel_function&lt;&lt;&lt;grid,block&gt;&gt;&gt;();</span><br><span class="line"><span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"><span class="type">double</span> Elaps = <span class="built_in">cpuSecond</span>() - start_time; </span><br><span class="line">cudaEvent_t startCuda, stopCuda;  <span class="comment">//declare</span></span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;startCuda);      <span class="comment">//set up </span></span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;stopCuda);       <span class="comment">//set up</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(startCuda,<span class="number">0</span>);    <span class="comment">//start</span></span><br><span class="line">myAdd &lt;&lt;&lt;grid, threads&gt;&gt;&gt; (d_B, d_C, d_A);</span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stopCuda,<span class="number">0</span>);     <span class="comment">//finish</span></span><br><span class="line"></span><br><span class="line"><span class="type">float</span> eTime;</span><br><span class="line"><span class="built_in">cudaEventElapsedTime</span>(&amp;eTime, startCuda, stopCuda); </span><br><span class="line"></span><br><span class="line">cout&lt;&lt;eTime&lt;&lt;endl;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaEventDestory</span>(startCuda);</span><br><span class="line"><span class="built_in">cudaEventDestory</span>(stopCuda);</span><br></pre></td></tr></table></figure>
<h2 id="7、获取GPU名字"><a href="#7、获取GPU名字" class="headerlink" title="7、获取GPU名字"></a>7、获取GPU名字</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cudaDeviceProp deviceProp;</span><br><span class="line"><span class="built_in">cudaGetDeviceProperties</span>(&amp;deviceProp, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;GPU Name: %s\nJob start:\n&quot;</span>, deviceProp.name);</span><br></pre></td></tr></table></figure>
<h2 id="8、线程束（Wrap"><a href="#8、线程束（Wrap" class="headerlink" title="8、线程束（Wrap)"></a>8、线程束（Wrap)</h2><p>线程束是SM中基本的执行单元</p>
<p>（SM是Streaming Multiprocessor的缩写，它是指图形处理器(GPU)中的一个核心处理单元）</p>
<p>一个线程束由32个连续的线程组成。是执行程序时的调度单位，同在一个warp的线程执行同一个指令。</p>
<p><strong>为什么要引入Wrap？</strong></p>
<p>虽然GPU的Grid和Block的大小很大，可以拥有上万级别的线程，但因为硬件的限制，不是所有线程都是可以平行运行的。在运行thread的时候， thread会被捆绑到一起形成一个wrap。32个thread一个wrap。 同一个wrap里的指令是一样的，也就是他们运行的东西是一摸一样的，数据也相同。一个wrap里的线程只允许在同一个block里面运行。<strong>为了让程序的运行更加有效，需要让同一个wrap里的线程运行同样的代码。</strong></p>
<p><strong>看一个代码：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">code_with_divergence</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> idx = threadIdx.x;</span><br><span class="line">	<span class="keyword">if</span>(idx%<span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		 <span class="comment">// do A</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">// do B</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这个这个代码会让效率减少一半。因为当运行A的时候，会让满足条件的那一半thread运行，而另一半的thread会被休眠。</p>
<p><strong>注意：</strong>不是写了if语句就一定会让运行效率降低。只要能保证用一个wrap里的线程运行同样的指令就可以提升效率，比如如下代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">code_without_divergence</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">	<span class="comment">// int wrap_id = idx/32;</span></span><br><span class="line">    <span class="type">int</span> wrap_id = idx / wrapSize;<span class="comment">//固有变量wrapSize = 32</span></span><br><span class="line">	<span class="keyword">if</span>(wrap_id%<span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		 <span class="comment">// do A</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">// do B</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码是以一个wrap为整体去运行的，所以不会影响运行效率。</p>
<h2 id="9、如何设置grid和block"><a href="#9、如何设置grid和block" class="headerlink" title="9、如何设置grid和block"></a>9、如何设置grid和block</h2><h3 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h3><p>GPU 由多个 SM 处理器构成，一个 SM 处理器包含 8 个 SP 核。一个 SM 处理器可同时处理 32 个线程（Wrap束），实际上是同一套指令在每个 SP 核上重复 4 次， 这样提交一次任务，8 个SP 核同时就能处理 32 个线程。</p>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1699013420617-1a677527-2101-48e4-a317-1841acc8d223.png" alt="img"></p>
<h3 id="设置grid和block维度"><a href="#设置grid和block维度" class="headerlink" title="设置grid和block维度"></a>设置grid和block维度</h3><p>如果某个GPU拥有 16 个 SM 处理器，共 128 个 SP 核（16*8）。</p>
<ol>
<li>如果想让每个 SM 处理器都工作，则 Grid 的 Block 的数量最好是 16 的整数倍。这样在整个计算过程中，每个 SM 处理器负载都是一样的。</li>
<li>每个 SM 处理器同时可以处理 32 个线程，因此，Block 中的线程数量最好是 32 的倍数，使得 8 个 SP 核负载均衡。</li>
</ol>
<p>由上可知，应该按照16<em>N</em>32<em>M = 512</em>S的划分模式，也就是说，理想的数据量应该是 512 的整数倍。同时要注意，一个线程块线程数量不能多于1024！</p>
<h4 id="1-一维grid，一维block"><a href="#1-一维grid，一维block" class="headerlink" title="1.一维grid，一维block"></a>1.一维grid，一维block</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> nx = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line"><span class="type">int</span> ny = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line"><span class="type">int</span> dimx = <span class="number">32</span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(dimx)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">((nx + block.x - <span class="number">1</span>) / block.x)</span></span>;</span><br></pre></td></tr></table></figure>
<p>核函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_function</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">if</span> (ix &lt; nx )</span><br><span class="line">   &#123;</span><br><span class="line">        <span class="built_in">do_something</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-二维grid，一维block"><a href="#2-二维grid，一维block" class="headerlink" title="2.二维grid，一维block"></a>2.二维grid，一维block</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> nx = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line"><span class="type">int</span> ny = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line"><span class="type">int</span> dimx = <span class="number">32</span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>, dimx)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(nx, (ny + block.y - <span class="number">1</span>) / block.y)</span></span>;</span><br></pre></td></tr></table></figure>
<p>核函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_function</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> x = blockIdx.x;</span><br><span class="line">    <span class="type">int</span> y = blockIdx.y*blockDim.y+threadIdx.y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-二维grid，二维block"><a href="#3-二维grid，二维block" class="headerlink" title="3.二维grid，二维block"></a>3.二维grid，二维block</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> nx = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line"><span class="type">int</span> ny = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line"><span class="type">int</span> dimx = <span class="number">32</span>;</span><br><span class="line"><span class="type">int</span> dimy = <span class="number">32</span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(dimx, dimy)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">((nx + block.x - <span class="number">1</span>) / block.x, (ny + block.y - <span class="number">1</span>) / block.y)</span></span>;</span><br></pre></td></tr></table></figure>
<p>核函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_function</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> tid = x*ny + y;</span><br><span class="line">    <span class="keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">do_something</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2022/02/05/CUDA%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/1699272791683-3f21b828-d2bd-4311-b305-d7185839e59d.png" alt="img"></p>
<h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/tardis/bd/art/566538074">https://www.zhihu.com/tardis/bd/art/566538074</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/573271688">https://zhuanlan.zhihu.com/p/573271688</a></p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
        <div id="lv-container"></div>
        <div class="giscus"></div>
    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    

<p id="hitokoto">加载中...</p>

<script>
    fetch('https://tenapi.cn/v2/yiyan')
        .then(response => response.text())
        .then(text => {
            document.getElementById('hitokoto').innerText = text;
        })
        .catch(error => {
            console.error('请求失败:', error);
        });
</script>
 <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
 </p>
</footer>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->






</html>
