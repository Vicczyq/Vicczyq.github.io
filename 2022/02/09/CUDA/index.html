<!DOCTYPE html>
<html lang=zh-CN>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        CUDA - Vicczyq | 记录学习和生活
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_28hi1hpxx24.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>

    









<meta name="generator" content="Hexo 7.1.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 好好生活，保持热爱，无惧无畏，奔赴山海 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar radius">
            <img src="//q2.qlogo.cn/headimg_dl?dst_uin=1740674168&amp;spec=140" />
        </div>
        <div class="name">
            <i>Vicczyq | 长木乔</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/collect/">
                    <i class="iconfont icon-shoucang1"></i>
                    <span>收藏</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E5%89%8D%E5%BA%8F"><span class="toc-text">一、前序</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E6%80%A7"><span class="toc-text">并行性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97"><span class="toc-text">异构计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gpu%E6%9E%B6%E6%9E%84"><span class="toc-text">GPU架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fermi-%E8%B4%B9%E7%B1%B3%E6%9E%B6%E6%9E%84"><span class="toc-text">Fermi 费米架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86"><span class="toc-text">补充知识</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88"><span class="toc-text">二、知识总览</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E5%9F%BA%E7%A1%80"><span class="toc-text">三、基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#gpu%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96"><span class="toc-text">3.1 GPU信息获取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%8B%E5%BA%8F%E5%86%85%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96"><span class="toc-text">3.1.1 程序内信息获取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvidia-smi"><span class="toc-text">3.1.2 nvidia-smi</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8Fhello-world"><span class="toc-text">3.2 第一个程序Hello world</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E4%B8%AA%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84"><span class="toc-text">整个代码结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-text">3.3 内存管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cudamemcpy"><span class="toc-text">3.2.1 cudaMemcpy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudamalloc"><span class="toc-text">3.2.2 cudaMalloc</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-text">3.2.3 示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E8%AF%86%E7%BA%BF%E7%A8%8B"><span class="toc-text">3.4 初识线程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-text">3.5 核函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86"><span class="toc-text">3.6 错误处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E6%97%B6"><span class="toc-text">3.7 计时</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cpu%E8%AE%A1%E6%97%B6%E6%B3%95"><span class="toc-text">3.7.1 CPU计时法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvprof"><span class="toc-text">3.7.2 nvprof</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F-warp"><span class="toc-text">3.8 线程束 Warp</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E5%88%86%E5%8C%96"><span class="toc-text">3.8.1 线程束分化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B5%84%E6%BA%90"><span class="toc-text">3.8.2 资源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%B6%E8%BF%9F%E9%9A%90%E8%97%8F"><span class="toc-text">3.8.3 延迟隐藏</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5"><span class="toc-text">3.9 同步</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E6%80%A7%E5%88%86%E6%9E%90"><span class="toc-text">3.10 并行性分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%A0%E7%94%A8%E7%8E%87%E5%88%86%E6%9E%90"><span class="toc-text">3.10.1 占用率分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E8%AF%BB%E5%8F%96%E6%95%88%E7%8E%87"><span class="toc-text">3.10.2 内存读取效率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%8A%A0%E8%BD%BD%E6%95%88%E7%8E%87"><span class="toc-text">3.10.3 全局加载效率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E9%AB%98%E5%B9%B6%E8%A1%8C%E6%80%A7"><span class="toc-text">3.10.4 提高并行性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96"><span class="toc-text">3.11 避免分支分化</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-bg" id="search-bg"></div>
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 好好生活，保持热爱，无惧无畏，奔赴山海 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        CUDA
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2022-02-09 13:26:27</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#超算" title="超算">超算</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p><strong>本篇参考：</strong></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://face2ai.com/program-blog">https://face2ai.com/program-blog</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34587739">https://zhuanlan.zhihu.com/p/34587739</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53773183">https://zhuanlan.zhihu.com/p/53773183</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/97044592">https://zhuanlan.zhihu.com/p/97044592</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sunmc1204953974/article/details/51000970">https://blog.csdn.net/sunmc1204953974/article/details/51000970</a></p></li>
</ul>
<p>学东西要沉住气，”<strong>慢就是稳，稳就是快</strong>“</p>
<h1 id="一前序">一、前序</h1>
<h2 id="并行性">并行性</h2>
<p>程序是一系列指令和数据的集合，因此并行就可以分为<strong>指令并行</strong>和<strong>数据并行</strong></p>
<p>我们通常更关注数据并行，openmp、pthread很多操作都是为了数据并行</p>
<ul>
<li>指令并行：利用流水线、‌超标量、‌乱序执行等技术，‌使得多条指令可以同时或部分重叠地执行</li>
<li>数据并行：在多个处理单元之间实现的，‌通过将数据划分成若干块，‌并分别映射到不同的处理单元上</li>
</ul>
<p>CUDA非常适合数据并行</p>
<h2 id="异构计算">异构计算</h2>
<p>异构：不同的计算机架构就是异构</p>
<p>x86 CPU+GPU的异构是最常见的</p>
<p><img src="/2022/02/09/CUDA/1.png"></p>
<ul>
<li>ALU：逻辑计算单元，也就是核心，就是我们常说的四核</li>
<li>Control：控制单元</li>
<li>Cache：缓存</li>
<li>DRAM：内存</li>
</ul>
<p>GPU中一个SM（红色框部分）可以看作是一个完整的多核CPU，只是ALU数量变多了，</p>
<p>因此GPU对数据量大的计算任务适应性更好，对于逻辑复杂的程序<strong>一个SM</strong>是不如<strong>一个CPU</strong></p>
<p><strong>注意：</strong>一个GPU是由若干多个SM（<em>streaming
multiprocessor</em>），可以把SM看成GPU的大核，寄存器register和共享内存shared
memory是SM的稀缺资源</p>
<p>CPU和GPU之间通过PCIe总线进行连接（有的采用的是NVLink）</p>
<h2 id="gpu架构">GPU架构</h2>
<p>GPU是围绕SM(流式多处理器)的扩展阵列搭建的，通过复制结构实现硬件并行。</p>
<p>GPU中每个SM都能支持数百个线程<strong>并发</strong>执行，</p>
<p>当一个核函数被启动的时候，<strong>多个block</strong>会被同时分配给可用的SM上执行。</p>
<h3 id="fermi-费米架构">Fermi 费米架构</h3>
<p>第一个完整的GPU架构，最大可支持16个SM，每个SM有32个Core，共512个Core</p>
<p><img src="/2022/02/09/CUDA/fermi.png"></p>
<p>其中一个SM的结构如下：</p>
<figure>
<img src="/2022/02/09/CUDA/fermi_sm-1723447691958-5.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1443485">https://cloud.tencent.com/developer/article/1443485</a></p>
<p><img src="/2022/02/09/CUDA/3_4.png"></p>
<p>其使用的是双Wrap调度机制，Wrap的线程数和运算单元数（Core）没必要关系，利用时钟周期，具体流程如下：</p>
<ul>
<li>第一个时钟周期：两个调度器调度不同两个Warp的16个线程（Half
Warp）到各自的16个Core上运算</li>
<li>第二个时钟周期：两个调度器调度剩余的Half Warp到Core上</li>
</ul>
<h2 id="补充知识">补充知识</h2>
<p>即是没有GPU，CPU也可以完成计算，只是速度会慢很多，所以把GPU看作是CPU的加速设备（加速卡）</p>
<p>NVIDIA目前的<strong>计算平台</strong>（不是架构）：</p>
<ul>
<li>Tegra：嵌入式芯片，功耗低，gpu和cpu芯片在同一块硅片上</li>
<li>Geforce：图像用户</li>
<li>Quadro：专业绘图，支持高速OpenGL渲染</li>
<li>Tesla：用于大规模并行计算</li>
</ul>
<p><strong>CUDA平台</strong>不是单单指软件或者硬件，而是建立在Nvidia
GPU上的一整套平台，并扩展出多语言支持</p>
<h1 id="二知识总览">二、知识总览</h1>
<figure>
<img src="/2022/02/09/CUDA/CUDA_C.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h1 id="三基础">三、基础</h1>
<h2 id="gpu信息获取">3.1 GPU信息获取</h2>
<h3 id="程序内信息获取">3.1.1 程序内信息获取</h3>
<p>具体参见：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45791458/article/details/136379581">https://blog.csdn.net/weixin_45791458/article/details/136379581</a></p>
<p>API在更新，最好是查阅最新的官方文档！</p>
<h3 id="nvidia-smi">3.1.2 nvidia-smi</h3>
<p>指令可以直接获取当前设备GPU信息，通过添加不同的参数获取不同的信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">root@dsw-425468-7489bfcb8-jfhdt:/mnt/workspace# nvidia-smi</span><br><span class="line">Sat Aug 10 22:43:58 2024       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 12.1     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  NVIDIA A10          Off  | 00000000:00:08.0 Off |                    0 |</span><br><span class="line">|  0%   29C    P8    15W / 150W |      0MiB / 22731MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>最具体的信息可以用如下命令查询</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi -q [-i No]</span><br></pre></td></tr></table></figure>
<p>更多用法可以<code>nvidia-smi -h</code> 或者 手册查询</p>
<h2 id="第一个程序hello-world">3.2 第一个程序Hello world</h2>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">print_kernel</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello CPU from GPU %d\n&quot;</span>, tid);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello GPU from CPU!\n&quot;</span>);</span><br><span class="line">    print_kernel&lt;&lt;&lt;<span class="number">1</span>,<span class="number">10</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceReset</span>();<span class="comment">//同步CPU和GPU</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2022/02/09/CUDA/image-20240810180059923.png"></p>
<ul>
<li><code>__global__</code>关键字告诉编译器此函数是在GPU上执行的核函数</li>
<li><code>print_kernel&lt;&lt;&lt;1,10&gt;&gt;&gt;()</code>运行核函数</li>
<li><code>cudaDeviceReset()</code>这个函数包含有隐式同步，CPU必须等GPU执行完成才接着执行，<code>cudaDeviceSynchronize()</code>则是显示同步</li>
</ul>
<h3 id="整个代码结构">整个代码结构</h3>
<ol type="1">
<li>分配GPU的内存</li>
<li>拷贝数据到GPU</li>
<li>调用核函数执行计算</li>
<li>将计算完的数据拷贝回主机</li>
<li>释放内存</li>
</ol>
<h2 id="内存管理">3.3 内存管理</h2>
<p>CUDA提供了一套进行内存管理的API，既可以管理设备端的内存也可以管理主机端的</p>
<p>但是主机端通常还是用传统的标准库进行管理。</p>
<table>
<thead>
<tr>
<th style="text-align: center;">标准C函数</th>
<th style="text-align: center;">CUDA API</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">malloc</td>
<td style="text-align: center;">cudaMalloc</td>
<td>分配内存</td>
</tr>
<tr>
<td style="text-align: center;">memcpy</td>
<td style="text-align: center;">cudaMemcpy</td>
<td>内存拷贝</td>
</tr>
<tr>
<td style="text-align: center;">memset</td>
<td style="text-align: center;">cudaMemst</td>
<td>数据设置</td>
</tr>
<tr>
<td style="text-align: center;">free</td>
<td style="text-align: center;">cudaFree</td>
<td>释放内存</td>
</tr>
</tbody>
</table>
<h3 id="cudamemcpy">3.2.1 cudaMemcpy</h3>
<p>内存数据拷贝的过程是通过总线完成的</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaMemcpy</span><span class="params">(<span class="type">void</span> * dst,<span class="type">const</span> <span class="type">void</span> * src,<span class="type">size_t</span> count,cudaMemcpyKind kind)</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">类型可以分为如下几种：</span></span><br><span class="line"><span class="comment">cudaMemcpyHostToHost</span></span><br><span class="line"><span class="comment">cudaMemcpyHostToDevice</span></span><br><span class="line"><span class="comment">cudaMemcpyDeviceToHost</span></span><br><span class="line"><span class="comment">cudaMemcpyDeviceToDevice</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p>如果函数执行成功，则会返回<code>cudaSuccess</code> 否则返回
<code>cudaErrorMemoryAllocation</code></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">char</span>* <span class="title function_">cudaGetErrorString</span><span class="params">(cudaError_t error)</span></span><br></pre></td></tr></table></figure>
<p>使用此指令即可把错误代码翻译成详细的信息</p>
<h3 id="cudamalloc">3.2.2 cudaMalloc</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMalloc</span> <span class="params">(<span class="type">void</span> **devPtr, <span class="type">size_t</span>  size )</span></span>; </span><br></pre></td></tr></table></figure>
<p>第一次遇到我也很好奇，为什么第一个参数是两个星星</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> *device_data=<span class="literal">NULL</span>;</span><br><span class="line"><span class="type">size_t</span> size = <span class="number">1024</span>*<span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"><span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;device_data, size);</span><br></pre></td></tr></table></figure>
<p>目的是为了将 device 上分配的内存地址通过形参传出来。</p>
<h3 id="示例">3.2.3 示例</h3>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span> <span class="comment">// For std::rand and std::srand</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ctime&gt;</span>   <span class="comment">// For std::time</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">sub_kernel</span><span class="params">(<span class="type">double</span> *a, <span class="type">double</span> *b, <span class="type">double</span> *res)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    res[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::<span class="built_in">srand</span>(std::<span class="built_in">time</span>(<span class="number">0</span>));</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nElement = <span class="number">32</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;The Number of Element is %d\n&quot;</span>, nElement);</span><br><span class="line">    <span class="type">double</span> *a_host = (<span class="type">double</span> *)<span class="built_in">malloc</span>(nElement * <span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="type">double</span> *b_host = (<span class="type">double</span> *)<span class="built_in">malloc</span>(nElement * <span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="type">double</span> *res_host = (<span class="type">double</span> *)<span class="built_in">malloc</span>(nElement * <span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="type">double</span> *res_from_gpu = (<span class="type">double</span> *)<span class="built_in">malloc</span>(nElement * <span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="built_in">memset</span>(res_host, <span class="number">0</span>, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="built_in">memset</span>(res_from_gpu, <span class="number">0</span>, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line"></span><br><span class="line">    <span class="type">double</span> *a_device, *b_device, *res_device;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">double</span> **)&amp;a_device, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">double</span> **)&amp;b_device, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">double</span> **)&amp;res_device, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*Init a b*/</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; nElement; i++)&#123;</span><br><span class="line">        a_host[i] = std::<span class="built_in">rand</span>() % <span class="number">100</span>;</span><br><span class="line">        b_host[i] = std::<span class="built_in">rand</span>() % <span class="number">100</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(a_device, a_host, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(b_device, b_host, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    sub_kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">32</span>&gt;&gt;&gt;(a_device, b_device, res_device);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; nElement; i++)&#123;</span><br><span class="line">        res_host[i] = a_host[i] + b_host[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(res_from_gpu, res_device, nElement*<span class="built_in">sizeof</span>(<span class="type">double</span>), cudaMemcpyDeviceToHost); </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; nElement; i++)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lf %lf\n&quot;</span>, res_host[i], res_from_gpu[i]);</span><br><span class="line">        <span class="keyword">if</span>(res_host[i]!=res_from_gpu[i])&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%d,ERROR!\n&quot;</span>,i);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(a_device);</span><br><span class="line">    <span class="built_in">cudaFree</span>(b_device);</span><br><span class="line">    <span class="built_in">cudaFree</span>(res_device);</span><br><span class="line">    <span class="built_in">free</span>(a_host);</span><br><span class="line">    <span class="built_in">free</span>(b_host);</span><br><span class="line">    <span class="built_in">free</span>(res_from_gpu);</span><br><span class="line">    <span class="built_in">free</span>(res_host);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="初识线程">3.4 初识线程</h2>
<p><img src="/2022/02/09/CUDA/4.png"></p>
<p>首先要明白，一个kernel对应一个Grid，一个Grid里面有很多块，每个块又可以包含许多线程</p>
<p>线程块内部线程之间可以实现<strong>同步</strong>和<strong>共享内存</strong>，不同线程块之间是<u>物理隔离</u>的</p>
<p><code>gridDim.x</code>、<code>gridDim.y</code>、<code>gridDim.z</code>分别表示<strong>Grid</strong>各个维度的大小</p>
<p><code>blockDim.x</code>、<code>blockDim.y</code>、<code>blockDim.z</code>分别表示<strong>线程块</strong>中各个维度的大小</p>
<p><code>blockIdx.x</code>、<code>blockIdx.y</code>、<code>blockIdx.z</code>分别表示<strong>当前线程块所处的线程格的坐标位置</strong></p>
<p><code>threadIdx.x</code>、<code>threadIdx.y</code>、<code>threadIdx.z</code>分别表示<strong>当前线程所处的线程块的坐标位置</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure>
<p><strong>注意：一个块里的线程最大为<u>1024</u></strong>，grid的维度（block的块数）很大，暂时可以不考虑</p>
<p>一维二维示意图如下，三维可自行推</p>
<p><img src="/2022/02/09/CUDA/1-1723297430375-3.png"></p>
<hr>
<p><img src="/2022/02/09/CUDA/cuda_thread.png"></p>
<p>计算出三维的线程编号： <span class="math display">\[
tid=threadIdx.x+threadIdx.y×blockDim.x+threadIdx.z×blockDim.x×blockDim.y
\]</span></p>
<h2 id="核函数">3.5 核函数</h2>
<p>所有CUDA核函数的启动都是异步的。</p>
<ul>
<li><code>__global__</code>：设备端运行，全局（主机端、设备端）都可以调用，<strong>返回类型必须是void</strong></li>
<li><code>__device__</code>：设备端运行</li>
<li><code>__host__</code>：忽略，不加关键词默认即这个</li>
</ul>
<p>有一个特殊情况，就是<code>__device__</code>和<code>__host__</code>同时存在，这样的话CPU和GPU就可以都进行调用，也可以存在返回值</p>
<p>底层实现是编译器编译出了两份功能相同，调用对象不同的代码</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__device__ __host__ <span class="type">int</span> <span class="title">func</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;GPU:%d\n&quot;</span>,<span class="built_in">func</span>(<span class="number">1</span>,<span class="number">1</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;CPU:%d\n&quot;</span>,<span class="built_in">func</span>(<span class="number">1</span>,<span class="number">1</span>));</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    kernel&lt;&lt;&lt;grid,block&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Kernel核函数编写有以下限制</p>
<ol type="1">
<li>只能访问设备内存</li>
<li>必须有void返回类型</li>
<li>不支持可变数量的参数</li>
<li><strong>不支持静态变量</strong></li>
<li>显示异步行为</li>
</ol>
<h2 id="错误处理">3.6 错误处理</h2>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK(call)\</span></span><br><span class="line"><span class="meta">&#123;\</span></span><br><span class="line"><span class="meta">  const cudaError_t <span class="keyword">error</span>=call;\</span></span><br><span class="line"><span class="meta">  <span class="keyword">if</span>(<span class="keyword">error</span>!=cudaSuccess)\</span></span><br><span class="line"><span class="meta">  &#123;\</span></span><br><span class="line"><span class="meta">      printf(<span class="string">&quot;ERROR: %s:%d,&quot;</span>,__FILE__,__LINE__);\</span></span><br><span class="line"><span class="meta">      printf(<span class="string">&quot;code:%d,reason:%s\n&quot;</span>,<span class="keyword">error</span>,cudaGetErrorString(<span class="keyword">error</span>));\</span></span><br><span class="line"><span class="meta">      exit(1);\</span></span><br><span class="line"><span class="meta">  &#125;\</span></span><br><span class="line"><span class="meta">&#125;</span></span><br></pre></td></tr></table></figure>
<p>通过这个宏定义就可以进行检查错误</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;a_d,nByte));</span><br></pre></td></tr></table></figure>
<h2 id="计时">3.7 计时</h2>
<h3 id="cpu计时法">3.7.1 CPU计时法</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">cpuSecond</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">timeval</span> tp;</span><br><span class="line">  <span class="built_in">gettimeofday</span>(&amp;tp,<span class="literal">NULL</span>);</span><br><span class="line">  <span class="keyword">return</span> ((<span class="type">double</span>)tp.tv_sec + (<span class="type">double</span>)tp.tv_usec*<span class="number">1e-6</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用这个方法计算得出的时间比GPU计算运行的时间要长</p>
<p>原因：</p>
<ul>
<li>主机调用核函数需要时间</li>
<li>主机同步函数需要时间</li>
</ul>
<h3 id="nvprof">3.7.2 nvprof</h3>
<p>nvprof是分析工具，可以很直观的计算出整个过程时间</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof [args] &lt;application&gt;</span><br></pre></td></tr></table></figure>
<p><img src="/2022/02/09/CUDA/image-20240811115225538.png"></p>
<p>可能会出现如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher.</span><br><span class="line">                  Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling.</span><br><span class="line">                  Refer https://developer.nvidia.com/tools-overview for more details.</span><br></pre></td></tr></table></figure>
<p>其实就是说nvprof工具太老了，让使用<code>NVIDIA Nsight Systems</code></p>
<p>具体参见：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/666242337">https://zhuanlan.zhihu.com/p/666242337</a></p>
<h2 id="线程束-warp">3.8 线程束 Warp</h2>
<p>warp是调度和运行的<strong>基本单元</strong>，CUDA
采用单指令多线程SIMT架构管理执行线程，</p>
<p>目前基本所有设备的线程束大小都是<strong>32</strong>，所以block大小最好是32的倍数</p>
<ul>
<li>被分配到同一个SM上的block是<strong>串行执行</strong>的。</li>
<li>一个block中不同warp是<strong>并发执行</strong>的。</li>
<li>一个warp中的32个线程是<strong>并行执行</strong>的。</li>
</ul>
<p><img src="/2022/02/09/CUDA/image-20240812175825376.png"></p>
<p>同一个warp内的线程通信，不需要进行同步（barrier）</p>
<h3 id="线程束分化">3.8.1 线程束分化</h3>
<p><code>if...else...</code>、<code>for</code>、<code>while</code>这些可以进行流控制，</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (con)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//do something</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//do something</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>假设这段代码是核函数的一部分，那么当一个线程束的32个线程执行这段代码的时候，如果其中16个执行if中的代码段，而另外16个执行else中的代码块，同一个线程束中的线程，执行不同的指令，这叫做线程束的分化。</p>
<p><strong>在同一周期内，同一个线程束的线程执行相同的指令，处理各自私有的数据</strong></p>
<p>因此，第一个指令周期运行if里面的指令，第二个指令周期才会运行else里面的指令</p>
<p>指令周期中，不满足条件的线程就什么也不执行，但是要占用core，所以效率很低。</p>
<p>要解决这个问题根本思路是<strong>避免同一个线程束内的线程分化</strong></p>
<p>有一个核函数 (低效)：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (tid % <span class="number">2</span>)&#123;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以改为</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> ((tid / warpSize) % <span class="number">2</span> == <span class="number">0</span>)&#123;</span><br><span class="line"></span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分支情况可以通过nvprof进行分析</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --metrics branch_efficiency [app]</span><br></pre></td></tr></table></figure>
<h3 id="资源">3.8.2 资源</h3>
<p>一个SM上被分配多少个线程块和线程束取决于SM中可用的<strong>寄存器</strong>和<strong>共享内存</strong>，以及内核需要的寄存器和共享内存大小。</p>
<p>当kernel占用的资源较少，那么更多的线程处于活跃状态，相反则线程越少。</p>
<p><img src="/2022/02/09/CUDA/image-20240812171813458.png"></p>
<h3 id="延迟隐藏">3.8.3 延迟隐藏</h3>
<p>其他类型的编程相比，GPU的延迟隐藏及其重要</p>
<p>指令延迟：计算指令从调用到完成所需时钟周期</p>
<p>➤ 算术类指令：10-20个时钟周期 ➤ 访存类指令：400-800个时钟周期</p>
<p>Q：<strong>如何计算满足延迟隐藏所需要的最小线程束数量？</strong></p>
<p>利特尔法则（Little’s Law） <span class="math display">\[
所需线程束数量 = 延迟时间×GPU吞吐量
\]</span> 假设在内核里一条指令的平均延迟是5个周期。为
了保持在每个周期内执行6个线程束的吞吐量，则至少需要30个未完成的线程束。</p>
<p><img src="/2022/02/09/CUDA/image-20240812172122110.png"></p>
<h2 id="同步">3.9 同步</h2>
<ul>
<li>系统级：CPU等待GPU完成工作</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaDeviceSynchronize</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>块级：线程块内所有线程完成工作</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__device__ <span class="type">void</span> __syncthreads();</span><br></pre></td></tr></table></figure>
<p>不同warp的线程需要进行同步后才能知道处理完的数据</p>
<p><strong>同一个wrap内的线程，不需要同步就可以知道</strong></p>
<p>可以说，块内同步是为了<u>同步warp之间的数据</u></p>
<h2 id="并行性分析">3.10 并行性分析</h2>
<p>由于我使用的是vGPU没办法进行分析，就参考书的内容进行整理。</p>
<p><img src="/2022/02/09/CUDA/image-20240812182613478.png"></p>
<p>据图可知，(32,16)的配置效率最高，推断其并行性更好，同一时刻有更多的线程块参与</p>
<h3 id="占用率分析">3.10.1 占用率分析</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --metrics achieved_occupancy ./simple_sum_matrix</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2022/02/09/CUDA/image-20240812182908474.png" alt="image-20240812182908474">
<figcaption aria-hidden="true">image-20240812182908474</figcaption>
</figure>
<blockquote>
<p>占用率：每周期内活跃线程束的平均数量与一个SM支持的线程束最大数量的比值</p>
</blockquote>
<p>可以看到，更高的占用率并不一 定意味着有更高的性能。</p>
<h3 id="内存读取效率">3.10.2 内存读取效率</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --metrics gld_throughput ./simple_sum_matrix</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2022/02/09/CUDA/image-20240812183610590.png" alt="image-20240812183610590">
<figcaption aria-hidden="true">image-20240812183610590</figcaption>
</figure>
<p>同样的，第四种情况吞吐量最高，但其速度还是慢</p>
<p>所以，更高的加载吞吐量并不一定意味着更高的性能。</p>
<h3 id="全局加载效率">3.10.3 全局加载效率</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --metrics gld_efficiency ./simple_sum_matrix</span><br></pre></td></tr></table></figure>
<p><img src="/2022/02/09/CUDA/image-20240812185301794.png"></p>
<p>全局加载效率：<strong>实际加载的数据量</strong>与<strong>理论上需要加载的数据量</strong>之间的比值。</p>
<blockquote>
<p>举个栗子：</p>
<p>假设你需要10个配料，厨房实际从仓库拿了20个配料，其中只有10个是你需要的。</p>
<ul>
<li><strong>所需的全局加载吞吐量</strong> =
10个配料（你真正需要的量）</li>
<li><strong>被请求的全局加载吞吐量</strong> =
20个配料（厨房实际带回的量）</li>
</ul>
<p>加载效率就为50%</p>
</blockquote>
<p>可以看到第一个和第二个的全局加载效率都很高，但是第一个速度也比较慢</p>
<h3 id="提高并行性">3.10.4 提高并行性</h3>
<p>由上面几个即可总结，</p>
<ol type="1">
<li>保证一个块的<strong>内层维数</strong>应该是线程束大小的倍数（block的x，横向）</li>
<li>线程块最内层维度的大小对性能起着的关键的作用</li>
<li>一个单独的指标不能产生最佳的性能，需要综合考虑寻找平衡点</li>
</ol>
<h2 id="避免分支分化">3.11 避免分支分化</h2>
<p>假设要对一个有N个元素的整数数组求和</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">	sum += array[i];</span><br></pre></td></tr></table></figure>
<p>我们要并行快速计算，有两种方式</p>
<p><strong>1.相邻配对</strong></p>
<p><img src="/2022/02/09/CUDA/image-20240812194414474.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 1; i &lt; N; i *= 2)&#123;</span><br><span class="line">	for(int j = 0; j + i &lt; N; j+=i)&#123;</span><br><span class="line">		data[j] += data[j+i];</span><br><span class="line">		//barrier</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>2.交错配对</strong></p>
<p><img src="/2022/02/09/CUDA/image-20240812194440973.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
        <div id="lv-container"></div>
        <div class="giscus"></div>
    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    

<p id="hitokoto">加载中...</p>

<script>
    fetch('https://tenapi.cn/v2/yiyan')
        .then(response => response.text())
        .then(text => {
            document.getElementById('hitokoto').innerText = text;
        })
        .catch(error => {
            console.error('请求失败:', error);
        });
</script>
 <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
 </p>
</footer>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->






</html>
